{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import mahotas\n",
    "import cv2\n",
    "import os\n",
    "import h5py\n",
    "images_per_class       = 800\n",
    "fixed_size             = tuple((256, 256))\n",
    "train_path             = \"dataset/train\"\n",
    "h5_train_data          = 'output/train_data.h5'\n",
    "h5_train_labels        = 'output/train_labels.h5'\n",
    "bins                   = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_bgr(image):\n",
    "    rgb_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return rgb_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bgr_hsv(rgb_img):\n",
    "    hsv_img = cv2.cvtColor(rgb_img, cv2.COLOR_RGB2HSV)\n",
    "    return hsv_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_segmentation(rgb_img,hsv_img):\n",
    "    lower_green = np.array([25,0,20])\n",
    "    upper_green = np.array([100,255,255])\n",
    "    healthy_mask = cv2.inRange(hsv_img, lower_green, upper_green)\n",
    "    result = cv2.bitwise_and(rgb_img,rgb_img, mask=healthy_mask)\n",
    "    lower_brown = np.array([10,0,10])\n",
    "    upper_brown = np.array([30,255,255])\n",
    "    disease_mask = cv2.inRange(hsv_img, lower_brown, upper_brown)\n",
    "    disease_result = cv2.bitwise_and(rgb_img, rgb_img, mask=disease_mask)\n",
    "    final_mask = healthy_mask + disease_mask\n",
    "    final_result = cv2.bitwise_and(rgb_img, rgb_img, mask=final_mask)\n",
    "    return final_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['diseased', 'healthy']\n"
     ]
    }
   ],
   "source": [
    "train_labels = os.listdir(train_path)\n",
    "train_labels.sort()\n",
    "print(train_labels)\n",
    "Hog_features = []\n",
    "labels       = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] processed folder: diseased\n",
      "[STATUS] processed folder: healthy\n",
      "[STATUS] completed Hog Feature Extraction...\n"
     ]
    }
   ],
   "source": [
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "for training_name in train_labels:\n",
    "    dir = os.path.join(train_path, training_name)\n",
    "    current_label = training_name\n",
    "    for x in range(1, images_per_class + 1):\n",
    "        file = os.path.join(dir, str(x) + \".jpg\")\n",
    "        image = cv2.imread(file)\n",
    "        image = cv2.resize(image, fixed_size)\n",
    "        RGB_BGR = rgb_bgr(image)\n",
    "        BGR_HSV = bgr_hsv(RGB_BGR)\n",
    "        IMG_SEGMENT = img_segmentation(RGB_BGR, BGR_HSV) \n",
    "        gray_image = cv2.cvtColor(IMG_SEGMENT, cv2.COLOR_BGR2GRAY)\n",
    "        fd_hog = hog(gray_image, orientations=9, pixels_per_cell=(8,8), cells_per_block=(2, 2), transform_sqrt=True, block_norm='L2-Hys')\n",
    "        labels.append(current_label)\n",
    "        Hog_features.append(fd_hog)\n",
    "    \n",
    "    print(\"[STATUS] processed folder: {}\".format(current_label))\n",
    "    \n",
    "print(\"[STATUS] completed Hog Feature Extraction...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] feature vector size (1600, 34596)\n"
     ]
    }
   ],
   "source": [
    "print(\"[STATUS] feature vector size {}\".format(np.array(Hog_features).shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] training Labels (1600,)\n"
     ]
    }
   ],
   "source": [
    "print(\"[STATUS] training Labels {}\".format(np.array(labels).shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] training labels encoded...\n"
     ]
    }
   ],
   "source": [
    "targetNames = np.unique(labels)\n",
    "le          = LabelEncoder()\n",
    "target      = le.fit_transform(labels)\n",
    "print(\"[STATUS] training labels encoded...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] feature vector normalized...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler            = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaled_features = scaler.fit_transform(Hog_features)\n",
    "print(\"[STATUS] feature vector normalized...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] target labels: [0 0 0 ... 1 1 1]\n",
      "[STATUS] target labels shape: (1600,)\n"
     ]
    }
   ],
   "source": [
    "print(\"[STATUS] target labels: {}\".format(target))\n",
    "print(\"[STATUS] target labels shape: {}\".format(target.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 34596)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescaled_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trees = 100\n",
    "test_size = 0.20\n",
    "seed      = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] splitted train and test data...\n",
      "Train data  : (1280, 34596)\n",
      "Test data   : (320, 34596)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "(trainDataHog, testDataHog, trainLabelsHog, testLabelsHog) = train_test_split(np.array(rescaled_features), np.array(target),test_size=test_size,random_state=seed)\n",
    "print(\"[STATUS] splitted train and test data...\")\n",
    "print(\"Train data  : {}\".format(trainDataHog.shape))\n",
    "print(\"Test data   : {}\".format(testDataHog.shape)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.82       158\n",
      "           1       0.84      0.78      0.81       162\n",
      "\n",
      "    accuracy                           0.81       320\n",
      "   macro avg       0.81      0.81      0.81       320\n",
      "weighted avg       0.81      0.81      0.81       320\n",
      "\n",
      "Accuracy: 0.8125\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "clf  = RandomForestClassifier(n_estimators=num_trees, random_state=seed)\n",
    "clf.fit(trainDataHog, trainLabelsHog)\n",
    "y_predict_RFC = clf.predict(testDataHog)\n",
    "cm_RFC = confusion_matrix(testLabelsHog, y_predict_RFC)\n",
    "print(classification_report(testLabelsHog, y_predict_RFC))\n",
    "accuracy_RFC = accuracy_score(testLabelsHog, y_predict_RFC)\n",
    "print(f\"Accuracy: {accuracy_RFC:}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testLabelsHog.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_RFC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82       158\n",
      "           1       0.82      0.84      0.83       162\n",
      "\n",
      "    accuracy                           0.83       320\n",
      "   macro avg       0.83      0.83      0.83       320\n",
      "weighted avg       0.83      0.83      0.83       320\n",
      "\n",
      "Accuracy: 0.828125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "#clf2 = LogisticRegression(random_state=seed) \n",
    "clf2 = LogisticRegression(random_state=seed,max_iter=1000) \n",
    "\n",
    "clf2.fit(trainDataHog, trainLabelsHog)\n",
    "\n",
    "y_predict_logistic = clf2.predict(testDataHog)\n",
    "\n",
    "cm_logistic = confusion_matrix(testLabelsHog, y_predict_logistic)\n",
    "\n",
    "print(classification_report(testLabelsHog, y_predict_logistic))\n",
    "\n",
    "accuracy_logistic = accuracy_score(testLabelsHog, y_predict_logistic)\n",
    "print(f\"Accuracy: {accuracy_logistic:}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.59      0.71       158\n",
      "           1       0.70      0.93      0.80       162\n",
      "\n",
      "    accuracy                           0.76       320\n",
      "   macro avg       0.79      0.76      0.75       320\n",
      "weighted avg       0.79      0.76      0.76       320\n",
      "\n",
      "Accuracy: 0.7625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "clf3 = KNeighborsClassifier(n_neighbors=5) \n",
    "\n",
    "clf3.fit(trainDataHog, trainLabelsHog)\n",
    "\n",
    "y_predict_SNS = clf3.predict(testDataHog)\n",
    "\n",
    "cm_SNS = confusion_matrix(testLabelsHog, y_predict_SNS)\n",
    "\n",
    "print(classification_report(testLabelsHog, y_predict_SNS))\n",
    "\n",
    "accuracy_SNS = accuracy_score(testLabelsHog, y_predict_SNS)\n",
    "print(f\"Accuracy: {accuracy_SNS:}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.72      0.68       158\n",
      "           1       0.69      0.62      0.66       162\n",
      "\n",
      "    accuracy                           0.67       320\n",
      "   macro avg       0.67      0.67      0.67       320\n",
      "weighted avg       0.67      0.67      0.67       320\n",
      "\n",
      "Accuracy: 0.66875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "clf4 = DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "clf4.fit(trainDataHog, trainLabelsHog)\n",
    "\n",
    "y_predict_DTC = clf4.predict(testDataHog)\n",
    "\n",
    "cm_DTC = confusion_matrix(testLabelsHog, y_predict_DTC)\n",
    "\n",
    "print(classification_report(testLabelsHog, y_predict_DTC))\n",
    "accuracy_DTC = accuracy_score(testLabelsHog, y_predict_DTC)\n",
    "print(f\"Accuracy: {accuracy_DTC:}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.54      0.61       158\n",
      "           1       0.63      0.77      0.70       162\n",
      "\n",
      "    accuracy                           0.66       320\n",
      "   macro avg       0.67      0.66      0.65       320\n",
      "weighted avg       0.67      0.66      0.65       320\n",
      "\n",
      "Accuracy: 0.659375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "clf5 = GaussianNB()\n",
    "\n",
    "clf5.fit(trainDataHog, trainLabelsHog)\n",
    "\n",
    "y_predict_GNB = clf5.predict(testDataHog)\n",
    "\n",
    "cm_GNB = confusion_matrix(testLabelsHog, y_predict_GNB)\n",
    "\n",
    "print(classification_report(testLabelsHog, y_predict_GNB))\n",
    "\n",
    "accuracy_GNB = accuracy_score(testLabelsHog, y_predict_GNB)\n",
    "print(f\"Accuracy: {accuracy_GNB:}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82       158\n",
      "           1       0.81      0.84      0.83       162\n",
      "\n",
      "    accuracy                           0.82       320\n",
      "   macro avg       0.82      0.82      0.82       320\n",
      "weighted avg       0.82      0.82      0.82       320\n",
      "\n",
      "Accuracy: 0.821875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "clf6 = SVC(kernel='linear')\n",
    "\n",
    "clf6.fit(trainDataHog, trainLabelsHog)\n",
    "\n",
    "y_predict_SVC = clf6.predict(testDataHog)\n",
    "\n",
    "cm_SVC = confusion_matrix(testLabelsHog, y_predict_SVC)\n",
    "\n",
    "print(classification_report(testLabelsHog, y_predict_SVC))\n",
    "\n",
    "accuracy_svc = accuracy_score(testLabelsHog, y_predict_SVC)\n",
    "print(f\"Accuracy: {accuracy_svc:}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Accuracy of Machine learning Models......\n",
      "SVC Accuracy => 0.821875\n",
      "Gaussian Naive Bayes Accuracy => 0.659375\n",
      "Decision Tree Classifier Accuracy => 0.66875\n",
      "Logistic Regression Accuracy => 0.828125\n",
      "k-nearest neighbors Accuracy => 0.7625\n",
      "Random Forest Classifier Accuracy =>0.8125\n"
     ]
    }
   ],
   "source": [
    "print(\"All Accuracy of Machine learning Models......\")\n",
    "print(f\"SVC Accuracy => {accuracy_svc}\")\n",
    "print(f\"Gaussian Naive Bayes Accuracy => {accuracy_GNB}\")\n",
    "print(f\"Decision Tree Classifier Accuracy => {accuracy_DTC}\")\n",
    "print(f\"Logistic Regression Accuracy => {accuracy_logistic}\")\n",
    "print(f\"k-nearest neighbors Accuracy => {accuracy_SNS}\")\n",
    "print(f\"Random Forest Classifier Accuracy =>{accuracy_RFC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2131546193.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[26], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    '''For The Hog Feature Extraction If Pixel Size is 16*16 vecotr size is (1600, 8100) and  the efficencies are following\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "'''For The Hog Feature Extraction If Pixel Size is 16*16 vecotr size is (1600, 8100) and  the efficencies are following\n",
    "All Accuracy of Machine learning Models......\n",
    "SVC Accuracy => 0.840625\n",
    "Gaussian Naive Bayes Accuracy => 0.678125\n",
    "Decision Tree Classifier Accuracy => 0.721875\n",
    "Logistic Regression Accuracy => 0.853125\n",
    "k-nearest neighbors Accuracy => 0.76875\n",
    "Random Forest Classifier Accuracy =>0.834375\n",
    "\n",
    "For The Hog Feature Extraction If Pixel Size is 32*32 vecotr size is (1600, 1764) and  the efficencies are following\n",
    "SVC Accuracy => 0.834375\n",
    "Gaussian Naive Bayes Accuracy => 0.7375\n",
    "Decision Tree Classifier Accuracy => 0.678125\n",
    "Logistic Regression Accuracy => 0.84375\n",
    "k-nearest neighbors Accuracy => 0.796875\n",
    "Random Forest Classifier Accuracy =>0.8375"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For The Hog Feature Extraction If Pixel Size is 16*16 vecotr size is (1600, 8100) and  the efficencies are following\n",
    "All Accuracy of Machine learning Models......\n",
    "SVC Accuracy => 0.840625\n",
    "Gaussian Naive Bayes Accuracy => 0.678125\n",
    "Decision Tree Classifier Accuracy => 0.721875\n",
    "Logistic Regression Accuracy => 0.853125\n",
    "k-nearest neighbors Accuracy => 0.76875\n",
    "Random Forest Classifier Accuracy =>0.834375\n",
    "\n",
    "For The Hog Feature Extraction If Pixel Size is 32*32 vecotr size is (1600, 1764) and  the efficencies are following\n",
    "SVC Accuracy => 0.834375\n",
    "Gaussian Naive Bayes Accuracy => 0.7375\n",
    "Decision Tree Classifier Accuracy => 0.678125\n",
    "Logistic Regression Accuracy => 0.84375\n",
    "k-nearest neighbors Accuracy => 0.796875\n",
    "Random Forest Classifier Accuracy =>0.8375\n",
    "\n",
    "For The Hog Feature Extraction If Pixel Size is 8*8 vecotr size is (1600, 34596) and  the efficencies are following\n",
    "All Accuracy of Machine learning Models......\n",
    "1.SVC Accuracy => 0.821875\n",
    "2.Gaussian Naive Bayes Accuracy => 0.659375\n",
    "3.Decision Tree Classifier Accuracy => 0.66875\n",
    "4.Logistic Regression Accuracy => 0.828125\n",
    "5.k-nearest neighbors Accuracy => 0.7625\n",
    "6.Random Forest Classifier Accuracy =>0.8125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''For The Hog Feature Extraction If Pixel Size is 16*16 vecotr size is (1600, 8100) and  the efficencies are following\n",
    "All Accuracy of Machine learning Models......\n",
    "1.SVC Accuracy => 0.840625\n",
    "2.Gaussian Naive Bayes Accuracy => 0.678125\n",
    "3.Decision Tree Classifier Accuracy => 0.721875\n",
    "4.Logistic Regression Accuracy => 0.853125\n",
    "5.k-nearest neighbors Accuracy => 0.76875\n",
    "6.Random Forest Classifier Accuracy =>0.834375\n",
    "\n",
    "For The Hog Feature Extraction If Pixel Size is 32*32 vecotr size is (1600, 1764) and  the efficencies are following\n",
    "1.SVC Accuracy => 0.834375\n",
    "2.Gaussian Naive Bayes Accuracy => 0.7375\n",
    "3.Decision Tree Classifier Accuracy => 0.678125\n",
    "4.Logistic Regression Accuracy => 0.84375\n",
    "5.k-nearest neighbors Accuracy => 0.796875\n",
    "6.Random Forest Classifier Accuracy =>0.8375\n",
    "\n",
    "For The Hog Feature Extraction If Pixel Size is 8*8 vecotr size is (1600, 34596) and  the efficencies are following\n",
    "All Accuracy of Machine learning Models......\n",
    "1.SVC Accuracy => 0.821875\n",
    "2.Gaussian Naive Bayes Accuracy => 0.659375\n",
    "3.Decision Tree Classifier Accuracy => 0.66875\n",
    "4.Logistic Regression Accuracy => 0.828125\n",
    "5.k-nearest neighbors Accuracy => 0.7625\n",
    "6.Random Forest Classifier Accuracy =>0.8125"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
