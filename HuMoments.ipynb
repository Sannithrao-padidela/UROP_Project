{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import mahotas\n",
    "import cv2\n",
    "import os\n",
    "import h5py\n",
    "images_per_class       = 800\n",
    "fixed_size             = tuple((256, 256))\n",
    "train_path             = \"dataset/train\"\n",
    "h5_train_data          = 'output/train_data.h5'\n",
    "h5_train_labels        = 'output/train_labels.h5'\n",
    "bins                   = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_bgr(image):\n",
    "    rgb_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return rgb_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bgr_hsv(rgb_img):\n",
    "    hsv_img = cv2.cvtColor(rgb_img, cv2.COLOR_RGB2HSV)\n",
    "    return hsv_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_segmentation(rgb_img,hsv_img):\n",
    "    lower_green = np.array([25,0,20])\n",
    "    upper_green = np.array([100,255,255])\n",
    "    healthy_mask = cv2.inRange(hsv_img, lower_green, upper_green)\n",
    "    result = cv2.bitwise_and(rgb_img,rgb_img, mask=healthy_mask)\n",
    "    lower_brown = np.array([10,0,10])\n",
    "    upper_brown = np.array([30,255,255])\n",
    "    disease_mask = cv2.inRange(hsv_img, lower_brown, upper_brown)\n",
    "    disease_result = cv2.bitwise_and(rgb_img, rgb_img, mask=disease_mask)\n",
    "    final_mask = healthy_mask + disease_mask\n",
    "    final_result = cv2.bitwise_and(rgb_img, rgb_img, mask=final_mask)\n",
    "    return final_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature-descriptor-1: Hu Moments\n",
    "def fd_hu_moments(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    feature = cv2.HuMoments(cv2.moments(image)).flatten()\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['diseased', 'healthy']\n"
     ]
    }
   ],
   "source": [
    "train_labels = os.listdir(train_path)\n",
    "train_labels.sort()\n",
    "print(train_labels)\n",
    "Hu_features = []\n",
    "labels       = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] processed folder: diseased\n",
      "[STATUS] processed folder: healthy\n",
      "[STATUS] completed Hu_Monents Feature Extraction...\n"
     ]
    }
   ],
   "source": [
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "for training_name in train_labels:\n",
    "    dir = os.path.join(train_path, training_name)\n",
    "    current_label = training_name\n",
    "    for x in range(1, images_per_class + 1):\n",
    "        file = os.path.join(dir, str(x) + \".jpg\")\n",
    "        image = cv2.imread(file)\n",
    "        image = cv2.resize(image, fixed_size)\n",
    "        RGB_BGR = rgb_bgr(image)\n",
    "        BGR_HSV = bgr_hsv(RGB_BGR)\n",
    "        IMG_SEGMENT = img_segmentation(RGB_BGR, BGR_HSV) \n",
    "        fv_hu_moments = fd_hu_moments(IMG_SEGMENT)\n",
    "        labels.append(current_label)\n",
    "        Hu_features.append(fv_hu_moments)\n",
    "    \n",
    "    print(\"[STATUS] processed folder: {}\".format(current_label))\n",
    "    \n",
    "print(\"[STATUS] completed Hu_Monents Feature Extraction...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] feature vector size (1600, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"[STATUS] feature vector size {}\".format(np.array(Hu_features).shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] training Labels (1600,)\n"
     ]
    }
   ],
   "source": [
    "print(\"[STATUS] training Labels {}\".format(np.array(labels).shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] training labels encoded...\n"
     ]
    }
   ],
   "source": [
    "targetNames = np.unique(labels)\n",
    "le          = LabelEncoder()\n",
    "target      = le.fit_transform(labels)\n",
    "print(\"[STATUS] training labels encoded...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] feature vector normalized...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler            = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaled_features = scaler.fit_transform(Hu_features)\n",
    "print(\"[STATUS] feature vector normalized...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] target labels: [0 0 0 ... 1 1 1]\n",
      "[STATUS] target labels shape: (1600,)\n"
     ]
    }
   ],
   "source": [
    "print(\"[STATUS] target labels: {}\".format(target))\n",
    "print(\"[STATUS] target labels shape: {}\".format(target.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 7)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescaled_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trees = 100\n",
    "test_size = 0.20\n",
    "seed      = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] splitted train and test data...\n",
      "Train data  : (1280, 7)\n",
      "Test data   : (320, 7)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "(trainDataHu, testDataHu, trainLabelsHu, testLabelsHu) = train_test_split(np.array(rescaled_features), np.array(target),test_size=test_size,random_state=seed)\n",
    "print(\"[STATUS] splitted train and test data...\")\n",
    "print(\"Train data  : {}\".format(trainDataHu.shape))\n",
    "print(\"Test data   : {}\".format(testDataHu.shape)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72       158\n",
      "           1       0.73      0.69      0.71       162\n",
      "\n",
      "    accuracy                           0.72       320\n",
      "   macro avg       0.72      0.72      0.72       320\n",
      "weighted avg       0.72      0.72      0.72       320\n",
      "\n",
      "Accuracy: 0.715625\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "clf  = RandomForestClassifier(n_estimators=num_trees, random_state=seed)\n",
    "clf.fit(trainDataHu, trainLabelsHu)\n",
    "y_predict_RFC = clf.predict(testDataHu)\n",
    "cm_RFC = confusion_matrix(testLabelsHu, y_predict_RFC)\n",
    "print(classification_report(testLabelsHu, y_predict_RFC))\n",
    "accuracy_rfc= accuracy_score(testLabelsHu, y_predict_RFC)\n",
    "print(f\"Accuracy: {accuracy_rfc:}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.74      0.68       158\n",
      "           1       0.69      0.57      0.62       162\n",
      "\n",
      "    accuracy                           0.65       320\n",
      "   macro avg       0.66      0.65      0.65       320\n",
      "weighted avg       0.66      0.65      0.65       320\n",
      "\n",
      "Accuracy: 0.653125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "#clf2 = LogisticRegression(random_state=seed) \n",
    "clf2 = LogisticRegression(random_state=seed,max_iter=1000) \n",
    "clf2.fit(trainDataHu, trainLabelsHu)\n",
    "y_predict_LR = clf2.predict(testDataHu)\n",
    "cm_logistic = confusion_matrix(testLabelsHu, y_predict_LR)\n",
    "print(classification_report(testLabelsHu, y_predict_LR))\n",
    "accuracy_LR= accuracy_score(testLabelsHu, y_predict_LR)\n",
    "print(f\"Accuracy: {accuracy_LR:}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71       158\n",
      "           1       0.72      0.70      0.71       162\n",
      "\n",
      "    accuracy                           0.71       320\n",
      "   macro avg       0.71      0.71      0.71       320\n",
      "weighted avg       0.71      0.71      0.71       320\n",
      "\n",
      "Accuracy: 0.709375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "clf3 = KNeighborsClassifier(n_neighbors=5)\n",
    "clf3.fit(trainDataHu, trainLabelsHu)\n",
    "y_predict_KNN = clf3.predict(testDataHu)\n",
    "cm_KNN = confusion_matrix(testLabelsHu, y_predict_KNN)\n",
    "print(classification_report(testLabelsHu, y_predict_KNN))\n",
    "accuracy_KNN= accuracy_score(testLabelsHu, y_predict_KNN)\n",
    "print(f\"Accuracy: {accuracy_KNN:}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.64       158\n",
      "           1       0.65      0.68      0.66       162\n",
      "\n",
      "    accuracy                           0.65       320\n",
      "   macro avg       0.65      0.65      0.65       320\n",
      "weighted avg       0.65      0.65      0.65       320\n",
      "\n",
      "Accuracy: 0.653125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "clf4 = DecisionTreeClassifier(random_state=seed)\n",
    "clf4.fit(trainDataHu, trainLabelsHu)\n",
    "y_predict_DTC= clf4.predict(testDataHu)\n",
    "cm_DTC = confusion_matrix(testLabelsHu, y_predict_DTC)\n",
    "print(classification_report(testLabelsHu, y_predict_DTC))\n",
    "accuracy_DTC= accuracy_score(testLabelsHu, y_predict_DTC)\n",
    "print(f\"Accuracy: {accuracy_DTC:}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69       158\n",
      "           1       1.00      0.11      0.20       162\n",
      "\n",
      "    accuracy                           0.55       320\n",
      "   macro avg       0.76      0.56      0.44       320\n",
      "weighted avg       0.76      0.55      0.44       320\n",
      "\n",
      "Accuracy: 0.55\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "clf5 = GaussianNB()\n",
    "clf5.fit(trainDataHu, trainLabelsHu)\n",
    "y_predict_GNB = clf5.predict(testDataHu)\n",
    "cm_GNB = confusion_matrix(testLabelsHu, y_predict_GNB)\n",
    "print(classification_report(testLabelsHu, y_predict_GNB))\n",
    "accuracy_GNB= accuracy_score(testLabelsHu, y_predict_GNB)\n",
    "print(f\"Accuracy: {accuracy_GNB:}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.87      0.72       158\n",
      "           1       0.79      0.48      0.59       162\n",
      "\n",
      "    accuracy                           0.67       320\n",
      "   macro avg       0.71      0.67      0.66       320\n",
      "weighted avg       0.71      0.67      0.66       320\n",
      "\n",
      "Accuracy: 0.671875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "clf6 = SVC(kernel='linear')\n",
    "clf6.fit(trainDataHu, trainLabelsHu)\n",
    "y_predict_SVC = clf6.predict(testDataHu)\n",
    "cm_SVC = confusion_matrix(testLabelsHu, y_predict_SVC)\n",
    "print(classification_report(testLabelsHu, y_predict_SVC))\n",
    "accuracy_SVC= accuracy_score(testLabelsHu, y_predict_SVC)\n",
    "print(f\"Accuracy: {accuracy_SVC:}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Accuracy of Machine learning Models......\n",
      "SVC Accuracy => 0.671875\n",
      "Gaussian Naive Bayes Accuracy => 0.55\n",
      "Decision Tree Classifier Accuracy => 0.653125\n",
      "Logistic Regression Accuracy => 0.653125\n",
      "k-nearest neighbors Accuracy => 0.709375\n",
      "Random Forest Classifier Accuracy =>0.715625\n"
     ]
    }
   ],
   "source": [
    "print(\"All Accuracy of Machine learning Models......\")\n",
    "print(f\"SVC Accuracy => {accuracy_SVC}\")\n",
    "print(f\"Gaussian Naive Bayes Accuracy => {accuracy_GNB}\")\n",
    "print(f\"Decision Tree Classifier Accuracy => {accuracy_DTC}\")\n",
    "print(f\"Logistic Regression Accuracy => {accuracy_LR}\")\n",
    "print(f\"k-nearest neighbors Accuracy => {accuracy_KNN}\")\n",
    "print(f\"Random Forest Classifier Accuracy =>{accuracy_rfc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (1391433233.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[48], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    '''All Accuracy of Machine learning Models......\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "'''All Accuracy of Machine learning Models......\n",
    "SVC Accuracy => 0.671875\n",
    "Gaussian Naive Bayes Accuracy => 0.55\n",
    "Decision Tree Classifier Accuracy => 0.653125\n",
    "Logistic Regression Accuracy => 0.653125\n",
    "k-nearest neighbors Accuracy => 0.709375\n",
    "Random Forest Classifier Accuracy =>0.715625"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Feature of Hu-Moments\n",
    "All Accuracy of Machine learning Models......\n",
    "SVC Accuracy => 0.671875\n",
    "Gaussian Naive Bayes Accuracy => 0.55\n",
    "Decision Tree Classifier Accuracy => 0.653125\n",
    "Logistic Regression Accuracy => 0.653125\n",
    "k-nearest neighbors Accuracy => 0.709375\n",
    "Random Forest Classifier Accuracy =>0.715625"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
