{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import mahotas\n",
    "import cv2\n",
    "import os\n",
    "import h5py\n",
    "images_per_class       = 800\n",
    "fixed_size             = tuple((256, 256))\n",
    "train_path             = \"dataset/train\"\n",
    "h5_train_data          = 'output/train_data.h5'\n",
    "h5_train_labels        = 'output/train_labels.h5'\n",
    "bins                   = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_bgr(image):\n",
    "    rgb_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return rgb_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bgr_hsv(rgb_img):\n",
    "    hsv_img = cv2.cvtColor(rgb_img, cv2.COLOR_RGB2HSV)\n",
    "    return hsv_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_segmentation(rgb_img,hsv_img):\n",
    "    lower_green = np.array([25,0,20])\n",
    "    upper_green = np.array([100,255,255])\n",
    "    healthy_mask = cv2.inRange(hsv_img, lower_green, upper_green)\n",
    "    result = cv2.bitwise_and(rgb_img,rgb_img, mask=healthy_mask)\n",
    "    lower_brown = np.array([10,0,10])\n",
    "    upper_brown = np.array([30,255,255])\n",
    "    disease_mask = cv2.inRange(hsv_img, lower_brown, upper_brown)\n",
    "    disease_result = cv2.bitwise_and(rgb_img, rgb_img, mask=disease_mask)\n",
    "    final_mask = healthy_mask + disease_mask\n",
    "    final_result = cv2.bitwise_and(rgb_img, rgb_img, mask=final_mask)\n",
    "    return final_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature-descriptor-3: Color Histogram\n",
    "def fd_histogram(image, mask=None):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist  = cv2.calcHist([image], [0, 1, 2], None, [bins, bins, bins], [0, 256, 0, 256, 0, 256])\n",
    "    cv2.normalize(hist, hist)\n",
    "    return hist.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['diseased', 'healthy']\n"
     ]
    }
   ],
   "source": [
    "train_labels = os.listdir(train_path)\n",
    "train_labels.sort()\n",
    "print(train_labels)\n",
    "Histogram_features = []\n",
    "labels       = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] processed folder: diseased\n",
      "[STATUS] processed folder: healthy\n",
      "[STATUS] completed Histogram Feature Extraction...\n"
     ]
    }
   ],
   "source": [
    "from skimage import exposure\n",
    "for training_name in train_labels:\n",
    "    dir = os.path.join(train_path, training_name)\n",
    "    current_label = training_name\n",
    "    for x in range(1, images_per_class + 1):\n",
    "        file = os.path.join(dir, str(x) + \".jpg\")\n",
    "        image = cv2.imread(file)\n",
    "        image = cv2.resize(image, fixed_size)\n",
    "        RGB_BGR = rgb_bgr(image)\n",
    "        BGR_HSV = bgr_hsv(RGB_BGR)\n",
    "        IMG_SEGMENT = img_segmentation(RGB_BGR, BGR_HSV) \n",
    "        fv_Histogram= fd_histogram(IMG_SEGMENT)\n",
    "        labels.append(current_label)\n",
    "        Histogram_features.append(fv_Histogram)\n",
    "    \n",
    "    print(\"[STATUS] processed folder: {}\".format(current_label))\n",
    "    \n",
    "print(\"[STATUS] completed Histogram Feature Extraction...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] feature vector size (1600, 512)\n"
     ]
    }
   ],
   "source": [
    "print(\"[STATUS] feature vector size {}\".format(np.array(Histogram_features).shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] training Labels (1600,)\n"
     ]
    }
   ],
   "source": [
    "print(\"[STATUS] training Labels {}\".format(np.array(labels).shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] training labels encoded...\n"
     ]
    }
   ],
   "source": [
    "targetNames = np.unique(labels)\n",
    "le          = LabelEncoder()\n",
    "target      = le.fit_transform(labels)\n",
    "print(\"[STATUS] training labels encoded...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] feature vector normalized...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler            = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaled_features = scaler.fit_transform(Histogram_features)\n",
    "print(\"[STATUS] feature vector normalized...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89868999, 0.03427632, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.97074117, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.96591603, 0.01332912, 0.02549925, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.9815963 , 0.01239635, 0.03557221, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.96860402, 0.01473364, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.9613786 , 0.0379812 , 0.09687979, ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] target labels: [0 0 0 ... 1 1 1]\n",
      "[STATUS] target labels shape: (1600,)\n"
     ]
    }
   ],
   "source": [
    "print(\"[STATUS] target labels: {}\".format(target))\n",
    "print(\"[STATUS] target labels shape: {}\".format(target.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 512)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescaled_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trees = 100\n",
    "test_size = 0.20\n",
    "seed      = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] splitted train and test data...\n",
      "Train data  : (1280, 512)\n",
      "Test data   : (320, 512)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "(trainDataHistogram, testDataHistogram, trainLabelsHistogram, testLabelsHistogram) = train_test_split(np.array(rescaled_features), np.array(target),test_size=test_size,random_state=seed)\n",
    "print(\"[STATUS] splitted train and test data...\")\n",
    "print(\"Train data  : {}\".format(trainDataHistogram.shape))\n",
    "print(\"Test data   : {}\".format(testDataHistogram.shape)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(testLabelsHistogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       158\n",
      "           1       0.97      0.98      0.98       162\n",
      "\n",
      "    accuracy                           0.97       320\n",
      "   macro avg       0.98      0.97      0.97       320\n",
      "weighted avg       0.98      0.97      0.97       320\n",
      "\n",
      "Accuracy: 0.975\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "clf  = RandomForestClassifier(n_estimators=num_trees, random_state=seed)\n",
    "clf.fit(trainDataHistogram, trainLabelsHistogram)\n",
    "y_predict_RFC = clf.predict(testDataHistogram)\n",
    "cm_RFC = confusion_matrix(testLabelsHistogram, y_predict_RFC)\n",
    "print(classification_report(testLabelsHistogram, y_predict_RFC))\n",
    "accuracy_rfc= accuracy_score(testLabelsHistogram, y_predict_RFC)\n",
    "print(f\"Accuracy: {accuracy_rfc:}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94       158\n",
      "           1       0.92      0.98      0.95       162\n",
      "\n",
      "    accuracy                           0.95       320\n",
      "   macro avg       0.95      0.95      0.95       320\n",
      "weighted avg       0.95      0.95      0.95       320\n",
      "\n",
      "Accuracy: 0.946875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "#clf2 = LogisticRegression(random_state=seed) \n",
    "clf2 = LogisticRegression(random_state=seed,max_iter=1000) \n",
    "clf2.fit(trainDataHistogram, trainLabelsHistogram)\n",
    "y_predict_LR = clf2.predict(testDataHistogram)\n",
    "cm_logistic = confusion_matrix(testLabelsHistogram, y_predict_LR)\n",
    "print(classification_report(testLabelsHistogram, y_predict_LR))\n",
    "accuracy_LR= accuracy_score(testLabelsHistogram, y_predict_LR)\n",
    "print(f\"Accuracy: {accuracy_LR:}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93       158\n",
      "           1       0.91      0.95      0.93       162\n",
      "\n",
      "    accuracy                           0.93       320\n",
      "   macro avg       0.93      0.93      0.93       320\n",
      "weighted avg       0.93      0.93      0.93       320\n",
      "\n",
      "Accuracy: 0.928125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "clf3 = KNeighborsClassifier(n_neighbors=5)\n",
    "clf3.fit(trainDataHistogram, trainLabelsHistogram)\n",
    "y_predict_KNN = clf3.predict(testDataHistogram)\n",
    "cm_KNN = confusion_matrix(testLabelsHistogram, y_predict_KNN)\n",
    "print(classification_report(testLabelsHistogram, y_predict_KNN))\n",
    "accuracy_KNN= accuracy_score(testLabelsHistogram, y_predict_KNN)\n",
    "print(f\"Accuracy: {accuracy_KNN:}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93       158\n",
      "           1       0.94      0.91      0.93       162\n",
      "\n",
      "    accuracy                           0.93       320\n",
      "   macro avg       0.93      0.93      0.93       320\n",
      "weighted avg       0.93      0.93      0.93       320\n",
      "\n",
      "Accuracy: 0.928125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "clf4 = DecisionTreeClassifier(random_state=seed)\n",
    "clf4.fit(trainDataHistogram, trainLabelsHistogram)\n",
    "y_predict_DTC= clf4.predict(testDataHistogram)\n",
    "cm_DTC = confusion_matrix(testLabelsHistogram, y_predict_DTC)\n",
    "print(classification_report(testLabelsHistogram, y_predict_DTC))\n",
    "accuracy_DTC= accuracy_score(testLabelsHistogram, y_predict_DTC)\n",
    "print(f\"Accuracy: {accuracy_DTC:}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.70      0.82       158\n",
      "           1       0.77      0.99      0.87       162\n",
      "\n",
      "    accuracy                           0.85       320\n",
      "   macro avg       0.88      0.85      0.84       320\n",
      "weighted avg       0.88      0.85      0.84       320\n",
      "\n",
      "Accuracy: 0.846875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "clf5 = GaussianNB()\n",
    "clf5.fit(trainDataHistogram, trainLabelsHistogram)\n",
    "y_predict_GNB = clf5.predict(testDataHistogram)\n",
    "cm_GNB = confusion_matrix(testLabelsHistogram, y_predict_GNB)\n",
    "print(classification_report(testLabelsHistogram, y_predict_GNB))\n",
    "accuracy_GNB= accuracy_score(testLabelsHistogram, y_predict_GNB)\n",
    "print(f\"Accuracy: {accuracy_GNB:}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       158\n",
      "           1       0.95      0.98      0.96       162\n",
      "\n",
      "    accuracy                           0.96       320\n",
      "   macro avg       0.96      0.96      0.96       320\n",
      "weighted avg       0.96      0.96      0.96       320\n",
      "\n",
      "Accuracy: 0.9625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "clf6 = SVC(kernel='linear')\n",
    "clf6.fit(trainDataHistogram, trainLabelsHistogram)\n",
    "y_predict_SVC = clf6.predict(testDataHistogram)\n",
    "cm_SVC = confusion_matrix(testLabelsHistogram, y_predict_SVC)\n",
    "print(classification_report(testLabelsHistogram, y_predict_SVC))\n",
    "accuracy_SVC= accuracy_score(testLabelsHistogram, y_predict_SVC)\n",
    "print(f\"Accuracy: {accuracy_SVC:}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Accuracy of Machine learning Models......\n",
      "SVC Accuracy => 0.9625\n",
      "Gaussian Naive Bayes Accuracy => 0.846875\n",
      "Decision Tree Classifier Accuracy => 0.928125\n",
      "Logistic Regression Accuracy => 0.946875\n",
      "k-nearest neighbors Accuracy => 0.928125\n",
      "Random Forest Classifier Accuracy =>0.975\n"
     ]
    }
   ],
   "source": [
    "print(\"All Accuracy of Machine learning Models......\")\n",
    "print(f\"SVC Accuracy => {accuracy_SVC}\")\n",
    "print(f\"Gaussian Naive Bayes Accuracy => {accuracy_GNB}\")\n",
    "print(f\"Decision Tree Classifier Accuracy => {accuracy_DTC}\")\n",
    "print(f\"Logistic Regression Accuracy => {accuracy_LR}\")\n",
    "print(f\"k-nearest neighbors Accuracy => {accuracy_KNN}\")\n",
    "print(f\"Random Forest Classifier Accuracy =>{accuracy_rfc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (1035519318.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[26], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    '''\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "For Histrogram Features The Accuracy of Model are Following\n",
    "All Accuracy of Machine learning Models......\n",
    "SVC Accuracy => 0.9625\n",
    "Gaussian Naive Bayes Accuracy => 0.846875\n",
    "Decision Tree Classifier Accuracy => 0.928125\n",
    "Logistic Regression Accuracy => 0.946875\n",
    "k-nearest neighbors Accuracy => 0.928125\n",
    "Random Forest Classifier Accuracy =>0.975"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All Accuracy of Machine learning Models......\n",
    "SVC Accuracy => 0.9625\n",
    "Gaussian Naive Bayes Accuracy => 0.846875\n",
    "Decision Tree Classifier Accuracy => 0.928125\n",
    "Logistic Regression Accuracy => 0.946875\n",
    "k-nearest neighbors Accuracy => 0.928125\n",
    "Random Forest Classifier Accuracy =>0.975"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
